# 缺陷修复需求文档

## 简介

MCP 工具 `search_knowledge` 在搜索知识库时，对于大型文档（如整本 PDF 书籍）返回了未经有效分块或截断的完整内容，导致上下文窗口溢出，会话异常终止。核心问题在于搜索结果的内容大小缺乏有效控制，存在多条内容泄漏路径。

## 缺陷分析

### 当前行为（缺陷）

1.1 WHEN 搜索命中一个大型 PDF 知识项（如整本书籍），且该知识项在导入时分块失败或未生成分块 THEN 系统降级为文档级搜索（`_item_search`），`SearchResult` 中携带完整的 `KnowledgeItem`，虽然 `content` 字段被截断为 200 字符，但 `matched_chunks` 为空列表，无法为调用方提供有效的分块内容片段

1.2 WHEN 搜索命中一个大型 PDF 知识项，且分块索引可用但分块内容本身过大（超过合理的上下文窗口限制） THEN 系统在 `_chunk_search` 路径中返回的 `matched_chunks` 和 `context_chunks` 包含未截断的大块内容，多个大分块的内容累加后可能超出上下文窗口限制

1.3 WHEN `search_knowledge` 核心方法构建搜索结果字典时 THEN 系统对 `matched_chunks` 和 `context_chunks` 中每个分块的 `content` 字段没有施加任何大小限制，也没有对所有分块内容的总大小进行控制

1.4 WHEN 大型 PDF 文档在导入时分块过程抛出异常 THEN 系统仅记录警告日志但不重试分块，导致该知识项永远没有分块数据，后续搜索只能走文档级降级路径

### 期望行为（正确）

2.1 WHEN 搜索命中一个大型知识项，且该知识项没有分块数据 THEN 系统应当对返回的 `content` 字段施加合理的大小限制（如最大 2000 字符），确保单个搜索结果不会导致上下文窗口溢出

2.2 WHEN 搜索通过分块路径返回 `matched_chunks` 和 `context_chunks` THEN 系统应当对每个分块的 `content` 字段施加最大长度限制，并对返回的分块总数量进行控制，确保搜索结果的总内容大小在可控范围内

2.3 WHEN `search_knowledge` 核心方法构建搜索结果字典时 THEN 系统应当计算所有返回内容（`content` + `matched_chunks` + `context_chunks`）的总大小，并在超出阈值时进行截断或裁剪，保证返回给 MCP 调用方的数据量不超过安全上限

2.4 WHEN 大型文档在导入时分块失败 THEN 系统应当在搜索时检测到缺失分块的情况，并按需对该知识项进行延迟分块（lazy chunking），或至少从完整内容中提取与查询相关的片段返回，而非返回空的 `matched_chunks`

### 不变行为（回归防护）

3.1 WHEN 搜索命中的知识项内容较短（如普通文本笔记、代码片段等，内容长度在合理范围内） THEN 系统应当继续正常返回完整的搜索结果，不受新增大小限制的影响

3.2 WHEN 搜索通过分块路径正常返回且分块大小在合理范围内 THEN 系统应当继续返回完整的 `matched_chunks` 和 `context_chunks` 内容，分块内容不被不必要地截断

3.3 WHEN 知识项在导入时分块成功 THEN 系统应当继续使用已有的分块数据进行搜索，分块搜索的精度和召回率不受影响

3.4 WHEN 搜索结果的过滤、排序、分组等功能被使用 THEN 系统应当继续正确执行这些操作，内容大小控制不影响结果的排序和过滤逻辑
